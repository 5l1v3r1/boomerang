#
# This file is part of the Boomerang Decompiler.
#
# See the file "LICENSE.TERMS" for information on usage and
# redistribution of this file, and for a DISCLAIMER OF ALL
# WARRANTIES.
#

ENDIANNESS BIG;


# General Purpose registers

INTEGER %g0[32] -> 0;
INTEGER %g1[32] -> 1;
INTEGER %g2[32] -> 2;
INTEGER %g3[32] -> 3;
INTEGER %g4[32] -> 4;
INTEGER %g5[32] -> 5;
INTEGER %g6[32] -> 6;
INTEGER %g7[32] -> 7;
INTEGER %g8[32] -> 8;
INTEGER %g9[32] -> 9;
INTEGER %g10[32] -> 10;
INTEGER %g11[32] -> 11;
INTEGER %g12[32] -> 12;
INTEGER %g13[32] -> 13;
INTEGER %g14[32] -> 14;
INTEGER %g15[32] -> 15;
INTEGER %g16[32] -> 16;
INTEGER %g17[32] -> 17;
INTEGER %g18[32] -> 18;
INTEGER %g19[32] -> 19;
INTEGER %g20[32] -> 20;
INTEGER %g21[32] -> 21;
INTEGER %g22[32] -> 22;
INTEGER %g23[32] -> 23;
INTEGER %g24[32] -> 24;
INTEGER %g25[32] -> 25;
INTEGER %g26[32] -> 26;
INTEGER %g27[32] -> 27;
INTEGER %g28[32] -> 28;
INTEGER %g29[32] -> 29;
INTEGER %g30[32] -> 30;
INTEGER %g31[32] -> 31;

# FP registers
FLOAT %f0[64] -> 32;
FLOAT %f1[64] -> 33;
FLOAT %f2[64] -> 34;
FLOAT %f3[64] -> 35;
FLOAT %f4[64] -> 36;
FLOAT %f5[64] -> 37;
FLOAT %f6[64] -> 38;
FLOAT %f7[64] -> 39;
FLOAT %f8[64] -> 40;
FLOAT %f9[64] -> 41;
FLOAT %f10[64] -> 42;
FLOAT %f11[64] -> 43;
FLOAT %f12[64] -> 44;
FLOAT %f13[64] -> 45;
FLOAT %f14[64] -> 46;
FLOAT %f15[64] -> 47;
FLOAT %f16[64] -> 48;
FLOAT %f17[64] -> 49;
FLOAT %f18[64] -> 50;
FLOAT %f19[64] -> 51;
FLOAT %f20[64] -> 52;
FLOAT %f21[64] -> 53;
FLOAT %f22[64] -> 54;
FLOAT %f23[64] -> 55;
FLOAT %f24[64] -> 56;
FLOAT %f25[64] -> 57;
FLOAT %f26[64] -> 58;
FLOAT %f27[64] -> 59;
FLOAT %f28[64] -> 60;
FLOAT %f29[64] -> 61;
FLOAT %f30[64] -> 62;
FLOAT %f31[64] -> 63;

# Vector registers
INTEGER %VRSAVE[32] -> 300;
INTEGER %VSCR[32] -> 301;
INTEGER %VR0[128] -> 302;
INTEGER %VR1[128] -> 303;
INTEGER %VR2[128] -> 304;
INTEGER %VR3[128] -> 305;
INTEGER %VR4[128] -> 306;
INTEGER %VR5[128] -> 307;
INTEGER %VR6[128] -> 308;
INTEGER %VR7[128] -> 309;
INTEGER %VR8[128] -> 310;
INTEGER %VR9[128] -> 311;
INTEGER %VR10[128] -> 312;
INTEGER %VR11[128] -> 313;
INTEGER %VR12[128] -> 314;
INTEGER %VR13[128] -> 315;
INTEGER %VR14[128] -> 316;
INTEGER %VR15[128] -> 317;
INTEGER %VR16[128] -> 318;
INTEGER %VR17[128] -> 319;
INTEGER %VR18[128] -> 320;
INTEGER %VR19[128] -> 321;
INTEGER %VR20[128] -> 322;
INTEGER %VR21[128] -> 323;
INTEGER %VR22[128] -> 324;
INTEGER %VR23[128] -> 325;
INTEGER %VR24[128] -> 326;
INTEGER %VR25[128] -> 327;
INTEGER %VR26[128] -> 328;
INTEGER %VR27[128] -> 329;
INTEGER %VR28[128] -> 330;
INTEGER %VR29[128] -> 331;
INTEGER %VR30[128] -> 332;
INTEGER %VR31[128] -> 333;

# Condition Registers (contains %CR0 to %CR7)
INTEGER %CR[32] -> 100;
INTEGER %CR0[4] -> 64 SHARES %CR@[0..3];
INTEGER %CR1[4] -> 65 SHARES %CR@[4..7];
INTEGER %CR2[4] -> 66 SHARES %CR@[8..11];
INTEGER %CR3[4] -> 67 SHARES %CR@[12..15];
INTEGER %CR4[4] -> 68 SHARES %CR@[16..19];
INTEGER %CR5[4] -> 69 SHARES %CR@[20..23];
INTEGER %CR6[4] -> 70 SHARES %CR@[24..27];
INTEGER %CR7[4] -> 71 SHARES %CR@[28..31];


INTEGER %LR[32]  -> -1;     # Link Register
INTEGER %CTR[32] -> -1;     # Count Register

INTEGER %XER[32] -> 200; # Fixed point exeption register
INTEGER %XERSO[1] -> 201 SHARES %XER@[31..31];
INTEGER %XEROV[1] -> 202 SHARES %XER@[30..30];
INTEGER %XERCA[1] -> 203 SHARES %XER@[29..29];

INTEGER %pc[32] -> -1;



SETXER(value) {
    *32* %XER := value
    *1* %XERCA := %XER@[29:29]
    *1* %XEROV := %XER@[30:30]
    *1* %XERSO := %XER@[31:31]
};

ADDFLAGSX(result, op1, op2) {
    *1*  %XERCA := ((op1@[31:31]) & (op2@[31:31])) | (~(result@[31:31]) & ((op1@[31:31]) | (op2@[31:31])))
    *1*  %XER@[29:29] := %XERCA
};

ADDFLAGSX0(result, op1, op2) {
    *1* %XERCA := ((op1@[31:31]) & (op2@[31:31])) | (~(result@[31:31]) & ((op1@[31:31]) | (op2@[31:31])))
    *1* %XER@[29:29] := %XERCA
    *1* %CR0@[0:0] := %XERSO
    *1* %CR0@[1:1] := [result = 0?1:0]
    *1* %CR0@[2:2] := [result > 0?1:0]
    *1* %CR0@[3:3] := [result < 0?1:0]
};

SUBFLAGSX(result, op1, op2) {
    *1*  %XERCA := (~(op1@[31:31]) & (op2@[31:31])) | ((result@[31:31]) & (~(op1@[31:31]) | (op2@[31:31])))
    *1*  %XER@[29:29] := %XERCA
};

SUBFLAGS0(result) {
    *1* %CR0@[0:0] := %XERSO
    *1* %CR0@[1:1] := [result = 0?1:0]
    *1* %CR0@[2:2] := [result > 0?1:0]
    *1* %CR0@[3:3] := [result < 0?1:0]
};

SUBFLAGSX0(result, op1, op2) {
    *1* %XERCA := (~(op1@[31:31]) & (op2@[31:31])) | ((result@[31:31]) & (~(op1@[31:31]) | (op2@[31:31])))
    *1* %XER@[29:29] := %XERCA
    *1* %CR0@[0:0] := %XERSO
    *1* %CR0@[1:1] := [result = 0?1:0]
    *1* %CR0@[2:2] := [result > 0?1:0]
    *1* %CR0@[3:3] := [result < 0?1:0]
};

SETFLAGS0(rd) {
    *1* %CR0@[0:0] := %XERSO            # Note: these are non IBM bit numbers; LT is most significant bit (PPC bit 0)
    *1* %CR0@[1:1] := [rd = 0?1:0]
    *1* %CR0@[2:2] := [rd > 0?1:0]
    *1* %CR0@[3:3] := [rd < 0?1:0]
};



SUBFLAGSNL(op1, op2, crfd) {
    # Set flags in Logical (unsigned) fashion
    *32* crfd = 0 => %CR0@[3:3] := op1 <u op2       *32* crfd = 0 => %CR0@[2:2] := op1 >u op2       *32* crfd = 0 => %CR0@[1:1] := op1 =  op2
    *32* crfd = 1 => %CR1@[3:3] := op1 <u op2       *32* crfd = 1 => %CR1@[2:2] := op1 >u op2       *32* crfd = 1 => %CR1@[1:1] := op1 =  op2
    *32* crfd = 2 => %CR2@[3:3] := op1 <u op2       *32* crfd = 2 => %CR2@[2:2] := op1 >u op2       *32* crfd = 2 => %CR2@[1:1] := op1 =  op2
    *32* crfd = 3 => %CR3@[3:3] := op1 <u op2       *32* crfd = 3 => %CR3@[2:2] := op1 >u op2       *32* crfd = 3 => %CR3@[1:1] := op1 =  op2
    *32* crfd = 4 => %CR4@[3:3] := op1 <u op2       *32* crfd = 4 => %CR4@[2:2] := op1 >u op2       *32* crfd = 4 => %CR4@[1:1] := op1 =  op2
    *32* crfd = 5 => %CR5@[3:3] := op1 <u op2       *32* crfd = 5 => %CR5@[2:2] := op1 >u op2       *32* crfd = 5 => %CR5@[1:1] := op1 =  op2
    *32* crfd = 6 => %CR6@[3:3] := op1 <u op2       *32* crfd = 6 => %CR6@[2:2] := op1 >u op2       *32* crfd = 6 => %CR6@[1:1] := op1 =  op2
    *32* crfd = 7 => %CR7@[3:3] := op1 <u op2       *32* crfd = 7 => %CR7@[2:2] := op1 >u op2       *32* crfd = 7 => %CR7@[1:1] := op1 =  op2
};

SUBFLAGSNS(op1, op2, crfd) {
    # Set flags in signed fashion
    *32* crfd = 0 => %CR0@[3:3] := op1 < op2        *32* crfd = 0 => %CR0@[2:2] := op1 > op2        *32* crfd = 0 => %CR0@[1:1] := op1 = op2
    *32* crfd = 1 => %CR1@[3:3] := op1 < op2        *32* crfd = 1 => %CR1@[2:2] := op1 > op2        *32* crfd = 1 => %CR1@[1:1] := op1 = op2
    *32* crfd = 2 => %CR2@[3:3] := op1 < op2        *32* crfd = 2 => %CR2@[2:2] := op1 > op2        *32* crfd = 2 => %CR2@[1:1] := op1 = op2
    *32* crfd = 3 => %CR3@[3:3] := op1 < op2        *32* crfd = 3 => %CR3@[2:2] := op1 > op2        *32* crfd = 3 => %CR3@[1:1] := op1 = op2
    *32* crfd = 4 => %CR4@[3:3] := op1 < op2        *32* crfd = 4 => %CR4@[2:2] := op1 > op2        *32* crfd = 4 => %CR4@[1:1] := op1 = op2
    *32* crfd = 5 => %CR5@[3:3] := op1 < op2        *32* crfd = 5 => %CR5@[2:2] := op1 > op2        *32* crfd = 5 => %CR5@[1:1] := op1 = op2
    *32* crfd = 6 => %CR6@[3:3] := op1 < op2        *32* crfd = 6 => %CR6@[2:2] := op1 > op2        *32* crfd = 6 => %CR6@[1:1] := op1 = op2
    *32* crfd = 7 => %CR7@[3:3] := op1 < op2        *32* crfd = 7 => %CR7@[2:2] := op1 > op2        *32* crfd = 7 => %CR7@[1:1] := op1 = op2
};

SETFFLAGSN(op1, op2, crfd) {
    # Set flags according to floating point compare
    *32* crfd = 0 => %CR0@[3:3] := op1 < op2        *32* crfd = 0 => %CR0@[2:2] := op1 > op2        *32* crfd = 0 => %CR0@[1:1] := op1 = op2
    *32* crfd = 1 => %CR1@[3:3] := op1 < op2        *32* crfd = 1 => %CR1@[2:2] := op1 > op2        *32* crfd = 1 => %CR1@[1:1] := op1 = op2
    *32* crfd = 2 => %CR2@[3:3] := op1 < op2        *32* crfd = 2 => %CR2@[2:2] := op1 > op2        *32* crfd = 2 => %CR2@[1:1] := op1 = op2
    *32* crfd = 3 => %CR3@[3:3] := op1 < op2        *32* crfd = 3 => %CR3@[2:2] := op1 > op2        *32* crfd = 3 => %CR3@[1:1] := op1 = op2
    *32* crfd = 4 => %CR4@[3:3] := op1 < op2        *32* crfd = 4 => %CR4@[2:2] := op1 > op2        *32* crfd = 4 => %CR4@[1:1] := op1 = op2
    *32* crfd = 5 => %CR5@[3:3] := op1 < op2        *32* crfd = 5 => %CR5@[2:2] := op1 > op2        *32* crfd = 5 => %CR5@[1:1] := op1 = op2
    *32* crfd = 6 => %CR6@[3:3] := op1 < op2        *32* crfd = 6 => %CR6@[2:2] := op1 > op2        *32* crfd = 6 => %CR6@[1:1] := op1 = op2
    *32* crfd = 7 => %CR7@[3:3] := op1 < op2        *32* crfd = 7 => %CR7@[2:2] := op1 > op2        *32* crfd = 7 => %CR7@[1:1] := op1 = op2
};


MR          rd, rs              *32* rd := rs;
LIS         rd, val             *32* rd := (val << 16);
LI          rd, val             *32* rd := sgnex(16, 32, val);

# Arithmetic operations

ADD         rd, ra, rb          *32* rd := ra + rb;
ADDq        rd, ra, rb          *32* rd := ra + rb              SETFLAGS0(rd);

ADDE        rd, ra, rb          *32* rd := ra + rb + %XERCA;
ADDEq       rd, ra, rb          *32* rd := ra + rb + %XERCA     SETFLAGS0(rd);

ADDI        rd, rs, simm        *32* rd := rs + sgnex(16, 32, simm);
ADDIC       rd, rs, simm        *32* rd := rs + simm            ADDFLAGSX(rd, rs, simm);    # Set carry
ADDICq      rd, rs, simm        *32* rd := rs + simm            ADDFLAGSX0(rd, rs, simm);   # Set carry and CR0
ADDIS       rd, rs, simm        *32* rd := rs + (simm << 16);

ADDME       rd, ra              *32* rd := ra + %XERCA - 1;
ADDMEq      rd, ra              *32* rd := ra + %XERCA - 1      SETFLAGS0(rd);

ADDZE       rd, ra              *32* rd := ra + %XERCA;
ADDZEq      rd, ra              *32* rd := ra + %XERCA          SETFLAGS0(rd);

DIVW        rd, ra, rb          *32* rd := ra / rb;
DIVWq       rd, ra, rb          *32* rd := ra / rb              SETFLAGS0(rd);

DIVWU       rd, ra, rb          *32* rd := ra / rb;
DIVWUq      rd, ra, rb          *32* rd := ra / rb              SETFLAGS0(rd);

EXTSB       rd, ra              *32* rd := sgnex(8, 32, ra);
EXTSBq      rd, ra              *32* rd := sgnex(8, 32, ra)     SETFLAGS0(rd);

MULLI       rd, ra, simm        *32* rd := ra * sgnex(16, 32, simm);
MULLW       rd, ra, rb          *32* rd := ra * rb;
MULLWq      rd, ra, rb          *32* rd := ra * rb              SETFLAGS0(rd);

SUBF        rd, ra, rb          *32* rd := rb - ra;
SUBFE       rd, ra, rb          *32* rd := rb + %XERCA - ra;

SUBFIC      rd, ra, simm        *32* rd := simm - ra            SUBFLAGSX(rd, simm, ra);
SUBFC       rd, ra, rb          *32* rd := rb - ra              SUBFLAGSX(rd, rb, ra);

SUBFCQ      rd, ra, rb          *32* rd := rb - ra              SUBFLAGSX0(rd, rb, ra);
SUBFCO      rd, ra, rb          *32* rd := rb - ra              SUBFLAGSX(rd, rb, ra);  # Also supposed to set overflow bits
SUBFCOQ     rd, ra, rb          *32* rd := rb - ra              SUBFLAGSX0(rd, rb, ra); # Also supposed to set overflow bits

NOP                             _;


# Logical ops
NEG         rd, ra              *32* rd := 0 - ra;
NEGq        rd, ra              *32* rd := 0 - ra               SETFLAGS0(rd);

AND         rd, ra, rb          *32* rd := ra & rb;
OR          rd, ra, rb          *32* rd := ra | rb;
XOR         rd, ra, rb          *32* rd := ra ^ rb;
ANDq        rd, ra, rb          *32* rd := ra & rb              SETFLAGS0(rd);
ORq         rd, ra, rb          *32* rd := ra | rb              SETFLAGS0(rd);
XORq        rd, ra, rb          *32* rd := ra ^ rb              SETFLAGS0(rd);

ANDIq       rd, rs, uimm        *32* rd := rs & uimm            SETFLAGS0(rd);  # Only ANDIq sets flags
ORI         rd, rs, uimm        *32* rd := rs | uimm;
XORI        rd, rs, uimm        *32* rd := rs ^ uimm;

ANDISq      rd, rs, uimm        *32* rd := rs & (uimm << 16)    SETFLAGS0(rd);  # Only ANDISq sets flags
ORIS        rd, rs, uimm        *32* rd := rs | (uimm << 16);
XORIS       rd, rs, uimm        *32* rd := rs ^ (uimm << 16);

NAND        rd, ra, rb          *32* rd := ~(ra & rb);
NOR         rd, ra, rb          *32* rd := ~(ra | rb);
EQV         rd, ra, rb          *32* rd := ~(ra ^ rb);
NANDq       rd, ra, rb          *32* rd := ~(ra & rb)           SETFLAGS0(rd);
NORq        rd, ra, rb          *32* rd := ~(ra | rb)           SETFLAGS0(rd);
EQVq        rd, ra, rb          *32* rd := ~(ra ^ rb)           SETFLAGS0(rd);

# Note: no ANDI or ANDIS (ANDIq and ANDISq instead)
# Note: no XORCR/XORCRq
ANDC        rd, ra, rb          *32* rd := ra & (~rb);
ORC         rd, ra, rb          *32* rd := ra | (~rb);
ANDCq       rd, ra, rb          *32* rd := ra & (~rb)           SETFLAGS0(rd);
ORCq        rd, ra, rb          *32* rd := ra | (~rb)           SETFLAGS0(rd);


# Shifts and rotates

# Note: SRAW/SRAWI also set the carry flag (%XERCA) in some weird way
SLW         Rd, Rs, op2         *32* Rd := Rs <<  op2;
SLWI        Rd, Rs, op2         *32* Rd := Rs <<  op2;
SRW         Rd, Rs, op2         *32* Rd := Rs >>  op2;
SRAW        Rd, Rs, op2         *32* Rd := Rs >>A op2;
SRAWI       Rd, Rs, op2         *32* Rd := Rs >>A op2;

SLWq        Rd, Rs, op2         *32* Rd := Rs <<  op2           SETFLAGS0(Rd);
SRWq        Rd, Rs, op2         *32* Rd := Rs >>  op2           SETFLAGS0(Rd);
SRAWq       Rd, Rs, op2         *32* Rd := Rs >>A op2           SETFLAGS0(Rd);
SRAWIq      Rd, Rs, op2         *32* Rd := Rs >>A op2           SETFLAGS0(Rd);

RLWINM      ra, rs, uimm, beg, end
        *32* tmp_mask := (1 << (32 - beg)) - (1 << (31 - end))
        *32* ra := rs rl uimm & tmp_mask                       # rl = rotate left
;

RLWINMq     ra, rs, uimm, beg, end
        *32* tmp_mask := (1 << (32 - beg)) - (1 << (31 - end))
        *32* ra := rs rl uimm & tmp_mask                       # rl = rotate left
        SETFLAGS0(ra)
;

RLWIMI      ra, rs, uimm, beg, end
        *32* tmp_mask := (1 << (32 - beg)) - (1 << (31 - end))
        *32* tmp_r := rs rl uimm & tmp_mask
        *32* ra := rs | (ra & ~tmp_mask)
;

RLWIMIq     ra, rs, uimm, beg, end
        *32* tmp_mask := (1 << (32 - beg)) - (1 << (31 - end))
        *32* tmp_r := rs rl uimm & tmp_mask
        *32* ra := rs | (ra & ~tmp_mask)
        SETFLAGS0(ra)
;

CLRLWI  rd, ra, ct      *32* rd := ra@[0:(32-ct)];


# Memory access. rA is passed twice; as part of eaddr, and by itself for the U versions (update rA)

LWZ         dest, src               *32* dest := src;
LWZX        dest, src               *32* dest := zfill(16, 32, src);
LBZ         dest, src               *32* dest := zfill(8, 32, src);
LHZ         dest, src               *32* dest := zfill(16, 32, src);
LHA         rd, eaddr, ra           *32* rd := sgnex(16, 32, m[eaddr]);
LBZX        rd, eaddr, ra           *32* rd := zfill(8, 32, m[eaddr]);

STWU        src, dest               *32* dest := src    *32* src := addr(dest);
STW         src, dest               *32* dest := src;
STWX        src, dest               *32* dest := src;
STH         src, dest               *16* dest := truncs(32, 16, src);
STHX        src, dest               *16* dest := truncs(32, 16, src);
STB         src, dest               *8*  dest := truncs(32, 8, src);
STBX        src, dest               *8*  dest := truncs(32, 8, src);


# Multi word load and store
LMW         s, dest     _;
STMW        s, dest     _;


# Floating point loads
LFD         dest, src               *64* dest := src;
LFDU        dest, src               *64* dest := src                        *32* src := addr(dest);
LFDX        dest, src               *64* dest := src;
LFDUX       dest, src               *64* dest := src                        *32* src := addr(dest);
LFS         dest, src               *32* dest := fsize(32, 64, src);
LFSU        dest, src               *32* dest := fsize(32, 64, src)         *32* src := addr(dest);
LFSX        dest, src               *32* dest := fsize(32, 64, src);
LFSUX       dest, src               *32* dest := fsize(32, 64, src)         *32* src := addr(dest);

# Floating point stores
STFD        fd, eaddr, ra           *64* m[eaddr] := fd;
STFDU       fd, eaddr, ra           *64* m[eaddr] := fd                     *32* ra := eaddr;
STFDX       fd, eaddr, ra           *64* m[eaddr] := fd;
STFDUX      fd, eaddr, ra           *64* m[eaddr] := fd                     *32* ra := eaddr;
STFS        fd, eaddr, ra           *32* m[eaddr] := fsize(64, 32, fd);
STFSU       fd, eaddr, ra           *32* m[eaddr] := fsize(64, 32, fd)      *32* ra := eaddr;
STFSX       fd, eaddr, ra           *32* m[eaddr] := fsize(64, 32, fd);
STFSUX      fd, eaddr, ra           *32* m[eaddr] := fsize(64, 32, fd)      *32* ra := eaddr;


BALLR                               *32* %pc := %LR;
MFLR        rd                      *32* rd := %LR;
MFCR        rd                      *32* rd := (%CR0 << 28) + (%CR1 << 24)
                                             + (%CR2 << 20) + (%CR3 << 16)
                                             + (%CR4 << 12) + (%CR5 <<  8)
                                             + (%CR6 <<  4) + (%CR7);

MFSPR       rd, spr                 *32* rd := [spr & 1 ? [spr >> 3 & 1 ? %CTR : %XER] : %LR];
MTLR        rs                      *32* %LR := rs;
MTXER       rs                      SETXER(rs);
MTCTR       rs                      *32* %CTR := rs;

BL          reloc                   *32* %LR := %pc + 4
                                    *32* %pc := reloc;

BLR                                 _; # Semantics are hard-coded (see CapstonePPCDecoder.cpp)

# Comparisons. Ignore XER[SO] for now.
CMP         crfd, ra, rb            SUBFLAGSNS(ra, rb, crfd);
CMPI        crfd, ra, simm          SUBFLAGSNS(ra, simm, crfd);
CMPW        ra, rb                  SUBFLAGSNL(ra, rb, 0);
CMPW        crfd, ra, rb            SUBFLAGSNL(ra, rb, crfd);
CMPWI       ra, simm                SUBFLAGSNS(ra, simm, 0);
CMPWI       crfd, ra, simm          SUBFLAGSNS(ra, simm, crfd);

CMPL        crfd, ra, rb            SUBFLAGSNL(ra, rb, crfd);
CMPLI       crfd, ra, uimm          SUBFLAGSNL(ra, uimm, crfd);
CMPLW       ra, rb                  SUBFLAGSNL(ra, rb, 0);
CMPLW       crfd, ra, rb            SUBFLAGSNL(ra, rb, crfd);
CMPLWI      ra, uimm                SUBFLAGSNL(ra, uimm, 0);
CMPLWI      crfd, ra, uimm          SUBFLAGSNL(ra, uimm, crfd);

FCMPO       crfd, fa, fb            SETFFLAGSN(fa, fb,crfd);    # Difference between O and U forms is
FCMPU       crfd, fa, fb            SETFFLAGSN(fa, fb,crfd);    # in exception handling


# condition register manipulation
CRCLR           d                   _;
CRAND           d, a, b             *1* d := a & b;
CROR            d, a, b             *1* d := a | b;
CRXOR           d, a, b             *1* d := a ^ b;
CRNAND          d, a, b             *1* d := ~(a & b);
CRNOR           d, a, b             *1* d := ~(a | b);
CREQV           d, a, b             *1* d := ~(a ^ b);
CRANDC          d, a, b             *1* d := a & (~b);
CRORC           d, a, b             *1* d := a | (~b);
# Note: no CRXORC


# Floating point operations
FMR             fd, fb            *64* fd := fb;
FMRq            fd, fb            *64* fd := fb;

FNEG            fd, fb            *64* fd := 0.0 -f fb;
FNEGq           fd, fb            *64* fd := 0.0 -f fb;

FRSP            fd, fb            *32* tmpf := fsize(64, 32, fb)        *64* fd := fsize(32, 64, tmpf);
FRSPq           fd, fb            *32* tmpf := fsize(64, 32, fb)        *64* fd := fsize(32, 64, tmpf);

FCTIW           fd, fb            *64* fd := zfill(32, 64, ftoi(64, 32, fb));
FCTIWq          fd, fb            *64* fd := zfill(32, 64, ftoi(64, 32, fb));

# The following are supposed to round towards 0 as well
FCTIWZ          fd, fb            *64* fd := zfill(32, 64, ftoi(64, 32, fb));
FCTIWZq         fd, fb            *64* fd := zfill(32, 64, ftoi(64, 32, fb));

FADD            fd, fa, fb        *64* fd := fa +f fb;
FADDq           fd, fa, fb        *64* fd := fa +f fb;        # Note: floating point flags not implemented yet

FADDS           fd, fa, fb        *64* fd := fa +f fb;        # Note: may only operate on 32 bits of precision
FADDSq          fd, fa, fb        *64* fd := fa +f fb;

FSUB            fd, fa, fb        *64* fd := fa -f fb;
FSUBq           fd, fa, fb        *64* fd := fa -f fb;

FSUBS           fd, fa, fb        *64* fd := fa -f fb;        # Note as above
FSUBSq          fd, fa, fb        *64* fd := fa -f fb;

FDIV            fd, fa, fb        *64* fd := fa /f fb;
FDIVq           fd, fa, fb        *64* fd := fa /f fb;

FDIVS           fd, fa, fb        *64* fd := fa /f fb;        # Note: only operates on 64/32 bits of precision
FDIVSq          fd, fa, fb        *64* fd := fa /f fb;        # Yet result is in 64-bit format

# conditional branch
# MVE: Not sure if I have the bit numbers round the right way (is LT 3 or 0?)
#
#CONDBR :=     { "%CR0@[3:3]",   "~%CR0@[2:2]",  "%CR0@[1:1]",   "~%CR0@[3:3]",
#                "%CR0@[2:2]",   "~%CR0@[3:3]",  "~%CR0@[1:1]",  "~%CR0@[2:2]",
#                "%CR0@[0:0]",   "~%CR0@[0:0]",  "%CR0@[0:0]",   "~%CR0@[0:0]"};
#
# Note: The semantics for the instructions below are still hard-coded so they are not defined explicitly.

# BRCONDS[IDX]    BIcr, reloc     *32* %pc := [(CONDBR[IDX] = 1) ? %pc+reloc : %pc];
b       dest            _;
blt     dest            _;
blt     cr, dest        _;
ble     dest            _;
ble     cr, dest        _;
beq     dest            _;
beq     cr, dest        _;
bge     dest            _;
bge     cr, dest        _;
bgt     dest            _;
bgt     cr, dest        _;
bnl     dest            _;
bnl     cr, dest        _;
bne     dest            _;
bne     cr, dest        _;
bng     dest            _;
bng     cr, dest        _;
bso     dest            _;
bso     cr, dest        _;
bns     dest            _;
bns     cr, dest        _;
bun     dest            _;
bun     cr, dest        _;
bnu     dest            _;
bnu     cr, dest        _;

# BRCONDSCTR[IDX] BIcr            *32* %pc := [(CONDBR[IDX] = 1) ? %CTR : %pc];
bltctr  BIcr            _;
blectr  BIcr            _;
beqctr  BIcr            _;
bgectr  BIcr            _;
bgtctr  BIcr            _;
bnlctr  BIcr            _;
bnectr  BIcr            _;
bngctr  BIcr            _;
bsoctr  BIcr            _;
bnsctr  BIcr            _;
bunctr  BIcr            _;
bnuctr  BIcr            _;

# BRCONDSLR[IDX]  BIcr            *32* %pc := [(CONDBR[IDX] = 1) ? %LR : %pc];
bltlr  BIcr            _;
blelr  BIcr            _;
beqlr  BIcr            _;
bgelr  BIcr            _;
bgtlr  BIcr            _;
bnllr  BIcr            _;
bnelr  BIcr            _;
bnglr  BIcr            _;
bsolr  BIcr            _;
bnslr  BIcr            _;
bunlr  BIcr            _;
bnulr  BIcr            _;

# Decrement CTR, branch conditionally
BDNZL   dest            *32* %LR := dest        *32* %CTR := %CTR - 1; # %pc update is hard-coded

BCTRL                   *32*%LR := %pc + 4      *32* %pc := %CTR;

# Trap instructions
TDI     cc, ra, simm    _;
TDGTI   ra, simm        _;
TDLTI   ra, simm        _;
TDLGTI  ra, simm        _;
TDLLTI  ra, simm        _;
TDNEI   ra, simm        _;
TDEQI   ra, simm        _;
TDUI    ra, simm        _;

TWI     cc, ra, simm    _;
TWGTI   ra, simm        _;
TWLTI   ra, simm        _;
TWNEI   ra, simm        _;
TWLGTI  ra, simm        _;
TWLLTI  ra, simm        _;
TWEQI   ra, simm        _;
TWUI    ra, simm        _;

# Vector instructions
VADDCUW vd, va, vb
    *64* tmp1 := zfill(32, 64, va@[0:31])   + zfill(32, 64, vb@[0:31])
    *64* tmp2 := zfill(32, 64, va@[32:63])  + zfill(32, 64, vb@[32:63])
    *64* tmp3 := zfill(32, 64, va@[64:95])  + zfill(32, 64, vb@[64:95])
    *64* tmp4 := zfill(32, 64, va@[96:127]) + zfill(32, 64, vb@[96:127])
    *32* vd@[0:31]   := zfill(1, 32, tmp1@[32:32])
    *32* vd@[32:63]  := zfill(1, 32, tmp2@[32:32])
    *32* vd@[64:95]  := zfill(1, 32, tmp3@[32:32])
    *32* vd@[96:127] := zfill(1, 32, tmp4@[32:32])
;

VADDFP vd, va, vb
    *32* vd@[0:31]   := va@[0:31]   +f vb@[0:31]
    *32* vd@[32:63]  := va@[32:63]  +f vb@[32:63]
    *32* vd@[64:95]  := va@[64:95]  +f vb@[64:95]
    *32* vd@[96:127] := va@[96:127] +f vb@[96:127]
;


VADDUBM vd, va, vb
    *8* vd@[0:7]     := (va@[0:7]     + vb@[0:7])     & 0xFF
    *8* vd@[8:15]    := (va@[8:15]    + vb@[8:15])    & 0xFF
    *8* vd@[16:23]   := (va@[16:23]   + vb@[16:23])   & 0xFF
    *8* vd@[24:31]   := (va@[24:31]   + vb@[24:31])   & 0xFF
    *8* vd@[32:39]   := (va@[32:39]   + vb@[32:39])   & 0xFF
    *8* vd@[40:47]   := (va@[40:47]   + vb@[40:47])   & 0xFF
    *8* vd@[48:55]   := (va@[48:55]   + vb@[48:55])   & 0xFF
    *8* vd@[56:63]   := (va@[56:63]   + vb@[56:63])   & 0xFF
    *8* vd@[64:71]   := (va@[64:71]   + vb@[64:71])   & 0xFF
    *8* vd@[72:79]   := (va@[72:79]   + vb@[72:79])   & 0xFF
    *8* vd@[80:87]   := (va@[80:87]   + vb@[80:87])   & 0xFF
    *8* vd@[88:95]   := (va@[88:95]   + vb@[88:95])   & 0xFF
    *8* vd@[96:103]  := (va@[96:103]  + vb@[96:103])  & 0xFF
    *8* vd@[104:111] := (va@[104:111] + vb@[104:111]) & 0xFF
    *8* vd@[112:119] := (va@[112:119] + vb@[112:119]) & 0xFF
    *8* vd@[120:127] := (va@[120:127] + vb@[120:127]) & 0xFF
;

VADDUHM vd, va, vb
    *16* vd@[0:15]    := (va@[0:15]    + vb@[0:15])    & 0xFFFF
    *16* vd@[15:31]   := (va@[15:31]   + vb@[15:31])   & 0xFFFF
    *16* vd@[32:47]   := (va@[32:47]   + vb@[32:47])   & 0xFFFF
    *16* vd@[48:63]   := (va@[48:63]   + vb@[48:63])   & 0xFFFF
    *16* vd@[64:79]   := (va@[64:79]   + vb@[64:79])   & 0xFFFF
    *16* vd@[80:95]   := (va@[80:95]   + vb@[80:95])   & 0xFFFF
    *16* vd@[96:111]  := (va@[96:111]  + vb@[96:111])  & 0xFFFF
    *16* vd@[112:127] := (va@[112:127] + vb@[112:127]) & 0xFFFF
;

VADDUWM vd, va, vb
    *32* vd@[0:31]    := (va@[0:31]    + vb@[0:31])    & 0xFFFFFFFF
    *32* vd@[32:63]   := (va@[32:63]   + vb@[32:63])   & 0xFFFFFFFF
    *32* vd@[64:95]   := (va@[64:95]   + vb@[64:95])   & 0xFFFFFFFF
    *32* vd@[96:127]  := (va@[96:127]  + vb@[96:127])  & 0xFFFFFFFF
;

VAND vd, va, vb
    *128* vd := va & vb
;

VANDC vd, va, vb
    *128* vd := va & ~vb
;

VSR vd, va, vb
    *128* vd := va >> vb@[125:127]
;

VUPKLSH vd, vb
    *32* vd@[0:31]   := sgnex(16, 32, vb@[0:15])
    *32* vd@[32:63]  := sgnex(16, 32, vb@[16:31])
    *32* vd@[64:95]  := sgnex(16, 32, vb@[32:47])
    *32* vd@[96:127] := sgnex(16, 32, vb@[48:63])
;

VXOR vd, va, vb
    *128* vd := va ^ vb
;

# Misc other instructions
ATTN                    _;
